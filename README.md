# hadoop-aws

# Ejemplo de MapReduce: Conteo de Palabras

Este documento describe el flujo de trabajo bÃ¡sico de un programa MapReduce para contar palabras en Hadoop.

## ğŸ“Œ Entrada
Ejemplo de archivo de texto:
```
Hadoop es rÃ¡pido
Hadoop es escalable
```

## ğŸ“Œ Fase Map
El Mapper divide el texto en palabras y genera pares clave-valor:
```
(Hadoop,1)
(es,1)
(rÃ¡pido,1)
(Hadoop,1)
(es,1)
(escalable,1)
```

## ğŸ“Œ Shuffle & Sort
Los pares clave-valor se agrupan y ordenan por clave:
```
(Hadoop, [1,1])
(es, [1,1])
(rÃ¡pido, [1])
(escalable, [1])
```

## ğŸ“Œ Fase Reduce
El Reducer suma los valores para cada clave:
```
(Hadoop,2)
(es,2)
(rÃ¡pido,1)
(escalable,1)
```

## ğŸ“Œ Salida final
Archivo con la frecuencia de cada palabra:
```
Hadoop	2
es	2
rÃ¡pido	1
escalable	1
```

## ğŸ“Œ Flujo de trabajo de MapReduce
1ï¸âƒ£ **Input Split:** Se divide el archivo en fragmentos para procesamiento paralelo.
2ï¸âƒ£ **Map:** Extrae, transforma y emite pares clave-valor.
3ï¸âƒ£ **Shuffle & Sort:** Agrupa los valores por clave.
4ï¸âƒ£ **Reduce:** Procesa los valores y genera la salida final.
5ï¸âƒ£ **Output:** Se almacena en HDFS o una base de datos externa.

## ğŸ“Œ Alternativas Modernas
- **Apache Spark:** Procesamiento en memoria mÃ¡s eficiente.
- **Apache Flink:** Procesamiento en tiempo real.

ğŸš€ *Este ejemplo se ejecuta usando Hadoop Streaming con scripts en Python.*

![image](https://github.com/user-attachments/assets/eefb9f12-aace-466d-819d-ada3daa10b70)

